---
title: Voice
description: Hands-free voice interaction with Beacon
---

Beacon supports hands-free voice interaction — say a wake word, ask a question, and hear the answer spoken back.

## How Voice Works

Voice interaction follows three steps:

1. **Wake word** — Beacon listens for a trigger phrase (e.g. "Hey Orin") using local detection
2. **Speech-to-text** — Your spoken question is transcribed via [Synapse](/grid/synapse)
3. **Text-to-speech** — The assistant's response is spoken aloud via [Synapse](/grid/synapse)

Wake word detection always runs locally for instant response. Transcription and speech synthesis route through Synapse, which dispatches to the configured upstream provider.

| Component | Local | Cloud (via Synapse) |
|-----------|-------|---------------------|
| Wake word detection | Yes | - |
| Speech-to-text | - | Whisper, Deepgram |
| Text-to-speech | - | OpenAI TTS, ElevenLabs |

## Setting Up Voice

### 1. Configure Synapse

Voice requires a running [Synapse](/grid/synapse) instance with at least one STT and one TTS provider configured. The simplest setup is an OpenAI key, which covers both:

| Provider | STT | TTS |
|----------|-----|-----|
| OpenAI | Whisper | OpenAI TTS |
| Deepgram | Yes | - |
| ElevenLabs | - | Yes |

Configure providers in your Synapse config file. See the [Synapse docs](/grid/synapse) for details.

### 2. Enable voice

Voice is enabled by default when Beacon starts with `--disable-voice` omitted. You can also toggle it in **Settings → Voice**.

### 3. Test it

Say your persona's wake word (default: **"Hey Orin"**), then ask a question.

## Wake Words

Each persona has its own wake words defined in its [persona.json](/codex/persona-json):

```json
{
  "voice": {
    "wakeWords": ["hey orin", "hi orin", "okay orin"]
  }
}
```

Wake word detection runs entirely on-device. No audio is sent anywhere until a wake word is detected.

### Customizing wake words

Edit your persona's `persona.json` to change or add wake words. See [Personas](/grid/beacon/personas) for details on persona customization.

## Voice Settings Per Persona

Voice settings live in the `voice` section of each persona's configuration:

```json
{
  "voice": {
    "wakeWords": ["hey orin"],
    "tts": {
      "voice": "nova",
      "speed": 1.0
    },
    "stt": {
      "model": "whisper-1"
    }
  }
}
```

Different personas can use different voices and STT models, so switching personas also changes the voice you hear. The TTS and STT model (e.g. `tts-1`, `whisper-1`) can be set globally via `BEACON_TTS_MODEL` and `BEACON_STT_MODEL` environment variables.

## Troubleshooting

### No response after wake word

- Check that your microphone is working and Beacon has permission to access it
- Verify Synapse is running and has an STT provider configured
- Try increasing the log level (`--verbose`) to see if the wake word is being detected

### Wake word triggers too easily

- Use longer, more distinct wake phrases (e.g. "Hey Orin" instead of just "Orin")
- Reduce the sensitivity if your persona supports it

### Voice sounds robotic or slow

- Try a different TTS voice in your persona's `voice.tts.voice` setting
- Adjust `voice.tts.speed` (1.0 is normal, 1.2 is slightly faster)
- Configure an ElevenLabs provider in Synapse for more natural-sounding voices
